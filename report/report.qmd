---
title: "Classification of verses into Testaments based on King James Bible"
author: "[Richard Mužík](mailto:richard@imuzik.cz)"
abstract: "Můj ukázkový abstrakt"
abstract-title: "Toto je abstrakt"
editor:
    render-on-save: true
execute:
    cache: true
date: today
format:
    html:
        toc: true
        embed-resources: true
        echo: true
        code-fold: true
        code-tools: true
        code-summary: "Show the code"
---

# Introduction

In this project we will explore the Bible, specifically King James Bible, in terms of data analysis.

## Goals and motivations

The main goal of this work is to create a classifier, that would take a verse and classify it to corresponding Testament respectively.

# Data

The King James Bible dataset contains full text of the Bible in the following format `Book Chapter:Verse    Text`:

- Book - name of the book where the verse can be found
- Chapter - chapter number
- Verse - verse number
- Text - text of the verse

```{python}
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

bible_df = pd.read_csv(
    "../data/bible.txt",
    sep="\t",
    header=None,
    names=["ref", "text"],
    engine="python",
)
parts = bible_df["ref"].str.extract(
    r"^(?P<book>.+?)\s+(?P<chapter>\d+):(?P<verse>\d+)$"
)

bible_df = pd.concat([parts, bible_df["text"]], axis=1)
bible_df.head()
```

## Data Quality Check

Now let's check if we have all data and if there are any duplicates:

```{python}
print(f"Total number of lines (verses): {len(bible_df)}")
print(f"Number of duplicate lines: {bible_df.duplicated().sum()}")
print(f"Number of unique books: {bible_df['book'].nunique()}")
print(f"Number of chapters: {bible_df.groupby(['book', 'chapter']).ngroups}")
print(f"Number of missing values:\n{bible_df.isna().sum()}")
```

As we can see, there are no duplicates and no missing values in our dataset.
I also managed to find \[[1](https://kingjamesbibledictionary.com/BibleFacts)\]\[[2](https://blackletterkingjamesbible.com/Library/BibleStatistics)\] that the King James Bible contains:

:::{.column-margin}
\[1\]: [https://kingjamesbibledictionary.com/BibleFacts](https://kingjamesbibledictionary.com/BibleFacts)

\[2\]: [https://blackletterkingjamesbible.com/Library/BibleStatistics](https://blackletterkingjamesbible.com/Library/BibleStatistics)
:::

- 66 books
- 1,189 chapters
- 31,102 verses

And indeed, our dataset contains exactly the same numbers.

## Exploratory Data Analysis

:::{.panel-tabset}

## Plot

```{python}
plt.figure(figsize=(8, 12))
sns.histplot(
    data=bible_df,
    y="book",
    hue="chapter",
    multiple="stack",
    palette="tab20",
    discrete=True,
    legend=False,
)
plt.xticks(rotation=90)
plt.title("Number of verses per book divided into chapters")
plt.ylabel("Book")
plt.xlabel("Number of verses")
plt.show()
```

## Data

```{python}
book_stats = bible_df.groupby("book").agg(
    num_chapters=("chapter", "nunique"),
    num_verses=("verse", "count"),
).reset_index()
book_stats
```

:::

As we can see from the histogram above, some books have significantly more verses than others.
For example, Psalms has the highest number of verses, while books like Obadiah and Philemon have very few verses.

Another thing that can be observed is that first half of the dataset (that should also correspond to Old Testament) has generally more verses per book compared to the second half (New Testament).

Let's now add a new column indicating whether the verse belongs to Old or New Testament.

```{python}
def assign_testament(book):
    old_testament_books = [
        # Historical books
        "Genesis", "Exodus", "Leviticus", "Numbers", "Deuteronomy", "Joshua", "Judges", "Ruth", "1 Samuel", "2 Samuel", "1 Kings", "2 Kings", "1 Chronicles", "2 Chronicles", "Ezra", "Nehemiah", "Esther",
        # Poetic books
        "Job", "Psalms", "Proverbs", "Ecclesiastes", "Song of Solomon",
        # Prophetic books
        "Isaiah", "Jeremiah", "Lamentations", "Ezekiel", "Daniel", "Hosea", "Joel", "Amos", "Obadiah", "Jonah", "Micah", "Nahum", "Habakkuk", "Zephaniah", "Haggai", "Zechariah", "Malachi"
    ]

    new_testament_books = [
        # Gospels:
        "Matthew", "Mark", "Luke", "John",
        # Historical:
        "Acts",
        # Epistles:
        "Romans", "1 Corinthians", "2 Corinthians", "Galatians", "Ephesians", "Philippians", "Colossians", "1 Thessalonians", "2 Thessalonians", "1 Timothy", "2 Timothy", "Titus", "Philemon", "Hebrews", "James", "1 Peter", "2 Peter", "1 John", "2 John", "3 John", "Jude",
        # The Revelation:
        "Revelation"
    ]

    if book in old_testament_books:
        return "Old Testament"
    elif book in new_testament_books:
        return "New Testament"
    else:
        return "Unknown"

bible_df["testament"] = bible_df["book"].apply(assign_testament)
bible_df.head()
```

Let's now check that we really have just Bible books:

```{python}
print(f"Unknown testaments present: {(bible_df['testament'] == 'Unknown').sum()}")
```

### Analysis per Testament

:::{.panel-tabset}
## Bible
```{python}
def basic_verses_chapters_books_stats(df, testament_name):
    print(f"Number of verses in {testament_name}: {len(df)}")
    print(f"Number of books in {testament_name}: {df['book'].nunique()}")
    print(f"Number of chapters in {testament_name}: {df.groupby(['book', 'chapter']).ngroups}")

def longest_shortest_books(df, testament_name):
    book_lengths = df.groupby('book').size()
    print(f"Longest book in {testament_name}: {book_lengths.idxmax()} ({book_lengths.max()} verses)")
    print(f"Shortest book in {testament_name}: {book_lengths.idxmin()} ({book_lengths.min()} verses)")

def average_verses_per_book(df, testament_name):
    book_lengths = df.groupby('book').size()
    average_verses = book_lengths.mean()
    print(f"Average number of verses per book in {testament_name}: {average_verses:.2f}")

def plot_top_words(df, testament_name, number_of_words=20):
    top_words = pd.Series(
        ' '.join(df['text']).lower().split()
    ).value_counts().head(number_of_words)

    plt.figure(figsize=(8, 6))
    sns.barplot(
        x=top_words.index,
        y=top_words.values,
        palette="viridis"
    )
    plt.xticks(rotation=90)
    plt.title(f"Top 20 most common words in {testament_name}")
    plt.xlabel("Words")
    plt.ylabel("Frequency")
    plt.show()
    return top_words

import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords

def plot_top_words_filtered(df, testament_name, stopwords, number_of_words=20):
    words = pd.Series(
        ' '.join(df['text']).lower().split()
    )
    filtered_words = words[~words.isin(stopwords)]
    top_words = filtered_words.value_counts().head(number_of_words)

    plt.figure(figsize=(8, 6))
    sns.barplot(
        x=top_words.index,
        y=top_words.values,
        palette="viridis"
    )
    plt.xticks(rotation=90)
    plt.title(f"Top 20 most common words in {testament_name} (filtered)")
    plt.xlabel("Words")
    plt.ylabel("Frequency")
    plt.show()
    return top_words

from wordcloud import WordCloud

def plot_wordcloud(df, testament_name):
    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(df['text']).lower())
    plt.figure(figsize=(10, 6))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')
    plt.title(f"Word Cloud for {testament_name}")
    plt.show()
```

```{python}
bible_df.head()
```

```{python}
basic_verses_chapters_books_stats(bible_df, "Bible")
```

```{python}
longest_shortest_books(bible_df, "Bible")
```

```{python}
average_verses_per_book(bible_df, "Bible")
```

:::{.panel-tabset}
## Plot
```{python}
top_words_bible = plot_top_words(bible_df, "Bible")
```

## Data
```{python}
print("Top 20 most common words in Bible")
print(top_words_bible)
```
:::

:::{.panel-tabset}
## Plot
```{python}
top_words_bible_filtered = plot_top_words_filtered(bible_df, "Bible", stopwords=set(stopwords.words('english')))
```

## Data
```{python}
print("Top 20 most common words in Bible (filtered)")
print(top_words_bible_filtered)
```
:::

```{python}
plot_wordcloud(bible_df, "Bible")
```


## Old Testament

```{python}
old_testament_df = bible_df[bible_df["testament"] == "Old Testament"]
old_testament_df.head()
```

```{python}
basic_verses_chapters_books_stats(old_testament_df, "Old Testament")
```

```{python}
longest_shortest_books(old_testament_df, "Old Testament")
```

```{python}
average_verses_per_book(old_testament_df, "Old Testament")
```

:::{.panel-tabset}
## Plot
```{python}
top_words_ot = plot_top_words(old_testament_df, "Old Testament")
```

## Data
```{python}
print("Top 20 most common words in Old Testament")
print(top_words_ot)
```
:::

:::{.panel-tabset}
## Plot
```{python}
top_words_ot_filtered = plot_top_words_filtered(old_testament_df, "Old Testament", stopwords=set(stopwords.words('english')))
```

## Data
```{python}
print("Top 20 most common words in Old Testament (filtered)")
print(top_words_ot_filtered)
```
:::

```{python}
plot_wordcloud(old_testament_df, "Old Testament")
```

## New Testament

```{python}
new_testament_df = bible_df[bible_df["testament"] == "New Testament"]
new_testament_df.head()
```

```{python}
basic_verses_chapters_books_stats(new_testament_df, "New Testament")
```

```{python}
longest_shortest_books(new_testament_df, "New Testament")
```

```{python}
average_verses_per_book(new_testament_df, "New Testament")
```

:::{.panel-tabset}
## Plot
```{python}
top_words_nt = plot_top_words(new_testament_df, "New Testament")
```

## Data
```{python}
print("Top 20 most common words in New Testament")
print(top_words_nt)
```
:::

:::{.panel-tabset}
## Plot
```{python}
top_words_nt_filtered = plot_top_words_filtered(new_testament_df, "New Testament", stopwords=set(stopwords.words('english')))
```

## Data
```{python}
print("Top 20 most common words in New Testament (filtered)")
print(top_words_nt_filtered)
```
:::

```{python}
plot_wordcloud(new_testament_df, "New Testament")
```

:::

# Modeling

```{python}
import re

def clean_text(text):
    text = text.lower()
    text = re.sub(r"[^a-z\s]", " ", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

bible_df["cleaned_text"] = bible_df["text"].apply(clean_text)
bible_df.head()
```

```{python}
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score

X_train, X_test, y_train, y_test = train_test_split(
    bible_df["cleaned_text"],
    bible_df["testament"],
    test_size=0.2,
    stratify=bible_df["testament"],
    random_state=42
)

tfidf = TfidfVectorizer(
    ngram_range=(1,2),
    analyzer="word",
    min_df=3,
    max_features=50000
)

X_train_tfidf = tfidf.fit_transform(X_train)
X_test_tfidf  = tfidf.transform(X_test)

clf = LogisticRegression(max_iter=500)
clf.fit(X_train_tfidf, y_train)

pred = clf.predict(X_test_tfidf)
print("Accuracy:", accuracy_score(y_test, pred))
print(classification_report(y_test, pred))
```

:::{.panel-tabset}

## Muži

## Ženy

## Ostatní

:::